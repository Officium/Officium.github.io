\documentclass[a4paper,11pt]{article}

\input{commands.tex}

\begin{document}
\title{Quantile Regression}
\author{Yanhua Huang}
\date{May 2019}
\maketitle

QRDQN is a notable distributional reinforcement algorithm. Instead of estimating probabilities of fixed atoms as in C51, it estimates the quantiles of the full distribution, which can be backpropagated by quantile loss. In this post, we will discuss quantile-like loss functions in statistic machine learning.

The first one is the mean squared error $\mathcal{L}_\mathrm{mse} = \mathbb{E}[(f(x) - y)^2]$. From 
\begin{equation}
\frac{\partial \mathcal{L}_{\mathrm{mse}}}{f(x)} = 0,
\end{equation}
we can get $f(x) = \mathbb{E}[y]$. 

The second one is the mean absolute error $\mathcal{L}_\mathrm{mae} = \mathbb{E}[|f(x) - y|]$. From 
\begin{equation}
\frac{\partial \mathcal{L}_{\mathrm{mse}}}{f(x)} = P(f(x)>y) - P(f(x) \le y) = 0,
\end{equation}
we can get $F(x) = 0.5$, i.e., $f(x)$ is the medium value of random variable $y$.

The last one is the quantile loss $\mathcal{L}_{\mathrm{quantile}}(\tau) = \mathbb{E}[\rho_\tau(f(x) - y)]$, where 
\begin{equation}
    \rho_\tau(a)= 
\begin{cases}
    \tau a,& \mathrm{if } a > 0\\
    (\tau - 1)a,& \mathrm{otherwise}
\end{cases}.
\end{equation}
From the same method in MAE, we can get $F(x) = 1 - \tau$, i.e., $f(x)$ is the $\tau$ quantile value of random variable $y$.


\end{document}